# SignLanguage - Traduction de la Langue des Signes en Temps RÃ©el

![SignLanguage App Banner](interface_screenshots/banner_readme.png)

## ğŸ“± Description

Ce projet prÃ©sente **SignLanguage**, une application mobile innovante de traduction de la langue des signes en temps rÃ©el, rÃ©alisÃ©e durant un stage de perfectionnement d'un mois Ã  la PÃ©piniÃ¨re d'Entreprises APII Mahdia (janvier 2026).

SignLanguage utilise l'intelligence artificielle (MediaPipe + TensorFlow Lite) pour reconnaÃ®tre les gestes de la main et les traduire instantanÃ©ment en texte et en parole dans trois langues (franÃ§ais, anglais, arabe). L'application atteint **90.3% de prÃ©cision** pour les lettres et **78.5% pour les mots**, avec une latence de seulement **75 millisecondes**.

Le projet combine dÃ©veloppement mobile (Flutter), apprentissage automatique (CNN, LSTM), vision par ordinateur (MediaPipe) et IoT (ESP32-CAM). Il rÃ©pond Ã  un besoin social rÃ©el en facilitant la communication pour environ **100 000 personnes sourdes en Tunisie**.

## âœ¨ FonctionnalitÃ©s

### ğŸ  Interface Moderne avec Glassmorphisme

L'application dispose dÃ©sormais de **5 Ã©crans modernes** avec un design glassmorphisme Ã©lÃ©gant :

1. **Ã‰cran d'accueil** - SÃ©lection du mode (Reconnaissance / Inverse)
2. **Mode Reconnaissance** - Gestes â†’ Texte/Parole
3. **Mode Inverse** - Voix/Texte â†’ Gestes
4. **SÃ©lection de langue** - ğŸ‡«ğŸ‡· FranÃ§ais, ğŸ‡¬ğŸ‡§ English, ğŸ‡¹ğŸ‡³ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
5. **Configuration ESP32-CAM** - CamÃ©ra distante

![Interfaces](interface_screenshots/Figure_23_Home_Screen.png)

### ğŸ”¤ Mode Reconnaissance (Gestes â†’ Texte/Parole)

- âœ… **Reconnaissance en temps rÃ©el** des gestes de la main (21 landmarks MediaPipe)
- âœ… **DÃ©tection de lettres** (A-Z, alphabet langue des signes)
- âœ… **DÃ©tection de mots** (BONJOUR, MERCI, SVP, OUI, NON, AU REVOIR)
- âœ… **Support multilingue** : FranÃ§ais, English, Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- âœ… **SynthÃ¨se vocale (TTS)** pour prononcer le texte traduit
- âœ… **Interface accessible** avec emojis pour personnes sourdes
- âœ… **Mode ESP32-CAM** pour camÃ©ra externe
- âœ… **Historique visuel** avec miniatures des gestes dÃ©tectÃ©s
- âœ… **Landmarks colorÃ©s** par doigt (pouce ğŸŸ , index ğŸŸ¢, majeur ğŸ”µ, annulaire ğŸ”´, auriculaire ğŸŸ£)

### ğŸ’¬ Mode Inverse (Voix/Texte â†’ Gestes)

- âœ… **Reconnaissance vocale (STT)** multilingue
- âœ… **Affichage sÃ©quentiel** des gestes correspondants
- âœ… **Animation lettre par lettre** avec images des gestes
- âœ… **ContrÃ´le de vitesse** : Lent (2s), Normal (1s), Rapide (0.5s)
- âœ… **Visualisation audio** avec forme d'onde animÃ©e
- âœ… **Interface intuitive** pour communication inverse

### ğŸŒ Gestion Multilingue

- ğŸ‡«ğŸ‡· **FranÃ§ais** (langue par dÃ©faut)
- ğŸ‡¬ğŸ‡§ **English** (traduction automatique)
- ğŸ‡¹ğŸ‡³ **Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©** (Arabe - innovation majeure pour le Maghreb)
- ğŸ’¾ **Sauvegarde des prÃ©fÃ©rences** (SharedPreferences)
- ğŸ”„ **Traduction dynamique** des phrases dÃ©tectÃ©es

### ğŸ“¡ ESP32-CAM

- âœ… **Configuration IP** avec validation
- âœ… **Test de connexion** (HTTP GET avec timeout)
- âœ… **Indicateur de statut** (ConnectÃ©/DÃ©connectÃ©)
- âœ… **Toggle camÃ©ra distante**
- âœ… **Streaming MJPEG** pour camÃ©ra externe

## ğŸ¯ Performance

| MÃ©trique | Valeur | Objectif |
|----------|--------|----------|
| PrÃ©cision Lettres | **90.3%** | â‰¥85% âœ… |
| PrÃ©cision Mots | **78.5%** | â‰¥75% âœ… |
| Latence | **75ms** | <100ms âœ… |
| FPS | **24** | â‰¥20 âœ… |
| Langues supportÃ©es | **3** | FR/EN/AR âœ… |
| Taille APK | **~45 MB** | <50MB âœ… |
| Ã‰crans | **5** | Interface moderne âœ… |

## ğŸ› ï¸ Technologies

### Frontend Mobile

- **Flutter 3.16+**: DÃ©veloppement mobile cross-platform
- **Dart**: Langage de programmation
- **Google Fonts**: Typographie Outfit

### Intelligence Artificielle

- **MediaPipe Hands**: DÃ©tection de 21 landmarks de la main
- **TensorFlow Lite**: ModÃ¨les d'IA on-device
  - CNN pour lettres (90.3% prÃ©cision)
  - LSTM pour mots (78.5% prÃ©cision)
- **Hand Landmarker Plugin**: IntÃ©gration Flutter

### Services

- **Flutter TTS**: SynthÃ¨se vocale multilingue
- **Speech to Text**: Reconnaissance vocale
- **Translator**: Traduction FR/EN/AR
- **SharedPreferences**: Sauvegarde prÃ©fÃ©rences

### IoT

- **ESP32-CAM**: Module camÃ©ra externe
- **HTTP**: Communication avec ESP32
- **MJPEG Streaming**: Flux vidÃ©o distant

## ğŸ¨ Design System

### Glassmorphisme

- **Effet blur** (BackdropFilter)
- **Semi-transparence** avec gradients
- **Bordures lumineuses** (gradient borders)
- **Ombres colorÃ©es** (box shadows)

### Palette de Couleurs

- Background: `#0a0a0a` (noir profond)
- Cards: `#111827` (gris foncÃ©)
- Primary: `#6366f1` (violet)
- Accent: `#06b6d4` (cyan)
- Text: `#f9fafb` (blanc)

### Typographie

- **Police**: Outfit (Google Fonts)
- **Poids**: 800 (Bold), 600 (SemiBold), 400 (Regular)

---

## ğŸ“ Architecture & Diagrammes

### Architecture Globale

L'application suit une architecture multi-couches moderne avec sÃ©paration des responsabilitÃ©s :

```mermaid
graph TB
    subgraph "PrÃ©sentation Layer"
        UI[UI Screens<br/>5 Ã©crans Flutter]
        Widgets[Shared Widgets<br/>Glassmorphism Components]
    end
    
    subgraph "Business Logic Layer"
        Camera[Camera Controller<br/>Frame Processing]
        Vision[MediaPipe<br/>Hand Landmarker]
        ML[TFLite Models<br/>CNN + LSTM]
    end
    
    subgraph "Data Layer"
        Prefs[SharedPreferences<br/>Settings]
        Assets[Assets<br/>Models + Images]
    end
    
    subgraph "Services"
        TTS[Flutter TTS<br/>Voice Synthesis]
        STT[Speech to Text<br/>Voice Recognition]
        Trans[Translator<br/>FR/EN/AR]
        ESP32[ESP32-CAM<br/>HTTP Stream]
    end
    
    UI --> Camera
    UI --> Vision
    Camera --> Vision
    Vision --> ML
    ML --> UI
    UI --> TTS
    UI --> STT
    UI --> Trans
    UI --> Prefs
    UI --> ESP32
```

### Cas d'Utilisation

![Diagramme Cas d'Utilisation](rapport_images/diagramme_cas_utilisation.png)

**Acteurs principaux** :

- ğŸ‘¤ **Utilisateur** : Personne sourde ou entendante utilisant l'app
- ğŸ“· **ESP32-CAM** : CamÃ©ra externe optionnelle

**Cas d'utilisation** :

1. DÃ©tecter gestes de la main
2. ReconnaÃ®tre lettres isolÃ©es
3. ReconnaÃ®tre mots en  sÃ©quence
4. Traduire en parole (TTS)
5. SÃ©lectionner langue de traduction
6. Mode inverse (Voix â†’ Gestes)
7. Configurer ESP32-CAM

### Diagramme de SÃ©quence - Mode Reconnaissance

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant RS as RecognitionScreen
    participant C as Camera
    participant HL as HandLandmarker
    participant TF as TFLite
    participant TTS as Text-to-Speech
    
    U->>RS: Ouvre Mode Reconnaissance
    RS->>C: Initialise camÃ©ra frontale
    C->>RS: CamÃ©ra prÃªte
    
    loop Toutes les 4 frames
        C->>HL: Envoie image (CameraImage)
        HL->>HL: DÃ©tecte 21 landmarks
        HL->>RS: Retourne landmarks normalisÃ©s
        RS->>RS: Rotation landmarks (camÃ©ra frontale)
        RS->>TF: Run inference (84 features)
        TF->>TF: CNN/LSTM prediction
        TF->>RS: Retourne (label, confidence)
        
        alt confidence > 0.85 (lettres) ou > 0.15 (mots)
            RS->>RS: Update buffer + voting
            RS->>U: Affiche lettre/mot
            U->>RS: Appuie sur ğŸ”Š
            RS->>TTS: speak(phrase, langue)
            TTS->>U: AudioOutput
        end
    end
```

![Diagramme SÃ©quence Reconnaissance](rapport_images/diagramme_sequence_reconnaissance.png)

### Diagramme de SÃ©quence - Mode Inverse

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant IS as InverseModeScreen
    participant STT as Speech-to-Text
    participant Assets as Gesture Assets
    
    U->>IS: Ouvre Mode Inverse
    U->>IS: Appuie sur bouton micro ğŸ¤
    IS->>STT: startListening(langue)
    
    loop Ã‰coute active
        U->>STT: Parle
        STT->>IS: onResult(texte reconnu)
        IS->>IS: Update recognizedText
        IS->>U: Affiche forme d'onde audio
    end
    
    U->>IS: Stop micro
    IS->>STT: stopListening()
    IS->>IS: startGestureAnimation()
    
    loop Pour chaque lettre
        IS->>Assets: Load gesture image (lettre_0.jpg)
        Assets->>IS: Image geste
        IS->>U: Affiche geste + highlight
        IS->>IS: Wait selon vitesse (0.5s-2s)
        IS->>IS: Increment currentLetterIndex
    end
    
    IS->>U: Animation complÃ¨te
```

![Diagramme SÃ©quence Mode Inverse](rapport_images/diagramme_sequence_mode_inverse.png)

### Diagramme de Classes

![Diagramme de Classes](rapport_images/diagramme_classes.png)

**Classes principales** :

```mermaid
classDiagram
    class RecognitionScreen {
        -CameraController _controller
        -HandLandmarkerPlugin _plugin
        -List~Hand~ _landmarks
        -String detectedText
        -String currentMode
        +initCamera()
        +processCameraImage()
        +runInferenceLetters()
        +runInferenceWords()
        +translatePhrase()
    }
    
    class InverseModeScreen {
        -SpeechToText _speech
        -String recognizedText
        -double _speed
        -int _currentLetterIndex
        +toggleListening()
        +startGestureAnimation()
    }
    
    class AppTheme {
        +Color primaryPurple
        +Color accentCyan
        +LinearGradient backgroundGradient
        +glassmorphismDecoration()
    }
    
    class HandPainter {
        -List~List~double~~ hands
        -int rotation
        -bool isFrontCamera
        +paint(Canvas, Size)
        +shouldRepaint()
    }
    
    class GlassmorphismCard {
        -EdgeInsets padding
        -double borderRadius
        -Widget child
        +build()
    }
    
    RecognitionScreen --> HandPainter : uses
    RecognitionScreen --> AppTheme : uses
    RecognitionScreen --> GlassmorphismCard : uses
    InverseModeScreen --> AppTheme : uses
    InverseModeScreen --> GlassmorphismCard : uses
```

### Architecture On-Device

![Architecture On-Device](rapport_images/architecture_on_device.png)

**Pipeline de traitement** :

1. **Capture** : CameraController (ResolutionPreset.low pour performance)
2. **DÃ©tection** : MediaPipe Hand Landmarker (21 points Ã— 2 mains)
3. **Normalisation** : Rotation + tri + normalisation des landmarks
4. **InfÃ©rence** : TFLite (CNN pour lettres, LSTM pour mots)
5. **Post-traitement** : Buffer voting + confidence thresholds
6. **Traduction** : Translator FR/EN/AR
7. **Sortie** : TTS multilingue

### Pipeline de DonnÃ©es

![Data Flow Pipeline](rapport_images/data_flow_pipeline_1769768053843.png)

### MÃ©triques de Performance

![Performance Metrics](rapport_images/performance_metrics_1769768116914.png)

**Optimisations** :

- âœ… Frame skipping (process every 4th frame)
- âœ… RÃ©solution camÃ©ra basse (low preset)
- âœ… Buffer voting (5 frames) pour stabilitÃ©
- âœ… Thresholds adaptatifs (0.85 lettres, 0.15 mots)
- âœ… Cooldown entre dÃ©tections (1.5s)

---

## ğŸ“¦ Installation

### PrÃ©requis

- Flutter SDK 3.16 ou supÃ©rieur
- Android Studio / VS Code
- Appareil Android (API 21+) ou Ã©mulateur

### Ã‰tapes

1. **Cloner le dÃ©pÃ´t**

```bash
git clone https://github.com/doosr/SignLanguageApp_Build.git
cd SignLanguageApp_Build
```

1. **Installer les dÃ©pendances Flutter**

```bash
cd flutter_app
flutter pub get
```

1. **VÃ©rifier les assets**

Les modÃ¨les TFLite et images de gestes sont dans `flutter_app/assets/` :

- `model_letters.tflite` (classificateur lettres)
- `model_words.tflite` (classificateur mots)
- `model_letters_labels.txt`
- `model_words_labels.txt`
- `gestures/*_0.jpg` (images des gestes A-Z)

1. **Build et exÃ©cution**

```bash
# Build APK debug
flutter build apk --debug

# Ou run en mode dÃ©veloppement
flutter run

# Build APK release (production)
flutter build apk --release --no-tree-shake-icons
```

## ğŸ”¬ Collecte de DonnÃ©es et EntraÃ®nement

### 1. CrÃ©er le Dataset

```bash
python create_dataset.py
# Suivez les instructions pour enregistrer les gestes
# GÃ©nÃ¨re: data.pickle (3000+ Ã©chantillons)
```

### 2. EntraÃ®ner les ModÃ¨les

```bash
python train_classifier.py
# GÃ©nÃ¨re: model_letters.tflite (90.3% prÃ©cision)
#         model_words.tflite (78.5% prÃ©cision)
```

### 3. Tester l'InfÃ©rence

```bash
python inference_classifier.py  # Mode lettres
python inference_sequence.py    # Mode mots
```

## ğŸ“ Structure du Projet

```
SignLanguageApp_Build/
â”œâ”€â”€ flutter_app/                    # Application mobile Flutter
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ main.dart              # Point d'entrÃ©e + navigation
â”‚   â”‚   â”œâ”€â”€ screens/               # 5 Ã©crans de l'app
â”‚   â”‚   â”‚   â”œâ”€â”€ home_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ recognition_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ inverse_mode_screen.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ language_selection_screen.dart
â”‚   â”‚   â”‚   â””â”€â”€ esp32_config_screen.dart
â”‚   â”‚   â”œâ”€â”€ widgets/               # Composants rÃ©utilisables
â”‚   â”‚   â”‚   â”œâ”€â”€ glassmorphism_card.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ gradient_button.dart
â”‚   â”‚   â”‚   â”œâ”€â”€ language_flag_button.dart
â”‚   â”‚   â”‚   â””â”€â”€ hand_painter.dart
â”‚   â”‚   â””â”€â”€ theme/
â”‚   â”‚       â””â”€â”€ app_theme.dart     # Design system
â”‚   â”œâ”€â”€ assets/                    # ModÃ¨les TFLite + images
â”‚   â”‚   â”œâ”€â”€ model_letters.tflite
â”‚   â”‚   â”œâ”€â”€ model_words.tflite
â”‚   â”‚   â”œâ”€â”€ model_letters_labels.txt
â”‚   â”‚   â”œâ”€â”€ model_words_labels.txt
â”‚   â”‚   â””â”€â”€ gestures/              # Images A-Z
â”‚   â”œâ”€â”€ android/                   # Configuration Android
â”‚   â””â”€â”€ pubspec.yaml               # DÃ©pendances
â”œâ”€â”€ esp32_cam/                     # Firmware ESP32-CAM
â”‚   â””â”€â”€ esp32_cam_stream.ino
â”œâ”€â”€ interface_screenshots/         # Mockups des Ã©crans
â”‚   â”œâ”€â”€ Figure_23_Home_Screen.png
â”‚   â”œâ”€â”€ Figure_24_Recognition_Mode.png
â”‚   â”œâ”€â”€ Figure_25_Inverse_Mode.png
â”‚   â”œâ”€â”€ Figure_26_Language_Selection.png
â”‚   â””â”€â”€ Figure_27_ESP32_Config.png
â”œâ”€â”€ create_dataset.py              # Collecte de donnÃ©es
â”œâ”€â”€ train_classifier.py            # EntraÃ®nement modÃ¨les
â”œâ”€â”€ inference_classifier.py        # Test lettres
â”œâ”€â”€ inference_sequence.py          # Test mots
â”œâ”€â”€ INTERFACE_MODERNE.md           # Documentation UI
â””â”€â”€ README.md
```

## ğŸŒ Mots-clÃ©s

`Langue des signes` â€¢ `Intelligence artificielle` â€¢ `Flutter` â€¢ `MediaPipe` â€¢ `TensorFlow Lite` â€¢ `AccessibilitÃ©` â€¢ `IoT` â€¢ `ESP32-CAM` â€¢ `Reconnaissance gestuelle` â€¢ `Vision par ordinateur` â€¢ `Inclusion sociale` â€¢ `Application mobile` â€¢ `Temps rÃ©el` â€¢ `On-device AI` â€¢ `Glassmorphisme` â€¢ `UI/UX` â€¢ `Speech-to-Text` â€¢ `Text-to-Speech`

## ğŸ“Š Utilisation

### Mode Reconnaissance

1. Ouvrir l'app **SignLanguage**
2. Sur l'Ã©cran d'accueil, appuyer sur **"Mode Reconnaissance"** ğŸ”¤
3. SÃ©lectionner le mode : **Lettres** (alphabet) ou **Mots** (vocabulaire)
4. Choisir la langue de sortie : ğŸ‡«ğŸ‡· FR / ğŸ‡¬ğŸ‡§ EN / ğŸ‡¹ğŸ‡³ AR
5. Faire des gestes devant la **camÃ©ra frontale**
6. La traduction s'affiche en **temps rÃ©el**
7. Appuyer sur ğŸ”Š pour **Ã©couter** la synthÃ¨se vocale

### Mode Inverse

1. Sur l'Ã©cran d'accueil, appuyer sur **"Mode Inverse"** ğŸ’¬
2. Appuyer sur le **bouton micro** ğŸ¤
3. **Parler** ou **dicter** le texte
4. Les gestes correspondants s'affichent **sÃ©quentiellement**
5. RÃ©gler la **vitesse** (Lent/Normal/Rapide)

## ğŸ† Impact Social

- **100 000 personnes sourdes** en Tunisie peuvent bÃ©nÃ©ficier de cette solution
- **Gratuit et accessible** : pas besoin d'interprÃ¨te (coÃ»t : 50-100 DT/heure)
- **Support de l'arabe** : innovation rare pour la communautÃ© maghrÃ©bine
- **On-device AI** : fonctionne sans internet
- **Interface accessible** : emojis et design intuitif pour faciliter l'usage
- **Mode bidirectionnel** : communication dans les deux sens

## ğŸš€ CI/CD avec GitHub Actions

### Build Automatique

Le projet utilise **GitHub Actions** pour build automatiquement l'APK Ã  chaque push :

```yaml
# .github/workflows/flutter-build.yml
- Build APK debug et release
- Tests automatiques
- Upload de l'APK en artifact
```

### TÃ©lÃ©charger l'APK

1. Aller dans l'onglet **Actions** sur GitHub
2. SÃ©lectionner le dernier workflow rÃ©ussi
3. TÃ©lÃ©charger l'artifact **app-release.apk**
4. Installer sur votre appareil Android

## ğŸ¯ Perspectives

### âœ… RÃ©alisÃ© (Janvier 2026)

- [x] DÃ©tection gestes en temps rÃ©el
- [x] ModÃ¨les CNN + LSTM performants
- [x] Support 3 langues (FR/EN/AR)
- [x] Interface moderne glassmorphisme
- [x] **Mode inverse : Voix â†’ Gestes**
- [x] ESP32-CAM intÃ©gration
- [x] 5 Ã©crans avec navigation fluide

### Court terme (3-6 mois)

- [ ] Extension vocabulaire (100 mots)
- [ ] Mode sombre/clair toggle
- [ ] DÃ©ploiement **Google Play Store**
- [ ] Tutorial interactif pour nouveaux utilisateurs
- [ ] AmÃ©lioration prÃ©cision modÃ¨les (95%+)

### Moyen terme (6-12 mois)

- [ ] Reconnaissance **expressions faciales**
- [ ] Grammaire **LSF** (Langue des Signes FranÃ§aise)
- [ ] DÃ©ploiement **iOS** (App Store)
- [ ] Mode **hors-ligne complet**
- [ ] Partage de phrases traduites

### Long terme (1-2 ans)

- [ ] Reconnaissance **continue** (phrases complexes)
- [ ] **RÃ©alitÃ© augmentÃ©e** (AR overlay)
- [ ] Support **ASL, BSL** et autres langues des signes
- [ ] **API cloud** pour traduction collaborative
- [ ] CommunautÃ© et dictionnaire collaboratif

## ğŸ“¸ Captures d'Ã‰cran

<table>
  <tr>
    <td><img src="interface_screenshots/Figure_23_Home_Screen.png" width="200"/><br/><b>Accueil</b></td>
    <td><img src="interface_screenshots/Figure_24_Recognition_Mode.png" width="200"/><br/><b>Reconnaissance</b></td>
    <td><img src="interface_screenshots/Figure_25_Inverse_Mode.png" width="200"/><br/><b>Mode Inverse</b></td>
  </tr>
  <tr>
    <td><img src="interface_screenshots/Figure_26_Language_Selection.png" width="200"/><br/><b>Langues</b></td>
    <td><img src="interface_screenshots/Figure_27_ESP32_Config.png" width="200"/><br/><b>ESP32-CAM</b></td>
    <td></td>
  </tr>
</table>

## ğŸ“„ Licence

MIT License - Libre d'utilisation et de modification

## ğŸ‘¨â€ğŸ’» Auteur

Projet rÃ©alisÃ© dans le cadre d'un **stage de perfectionnement**  
ğŸ“ **PÃ©piniÃ¨re d'Entreprises APII Mahdia** (Janvier 2026)  
ğŸ“ **ISET Mahdia** - DSI 2024-2025  

## ğŸ™ Remerciements

- **PÃ©piniÃ¨re d'Entreprises APII Mahdia** pour l'accueil et l'encadrement
- Programme **"startup APII"** (Janvier 2026)
- **ISET Mahdia** - DÃ©partement DSI
- **CommunautÃ© sourde tunisienne** pour les retours et tests
- **Google MediaPipe Team** pour les outils de vision
- **Flutter Team** pour le framework exceptionnel

---

<p align="center">
  <b>SignLanguage</b> - Briser les barriÃ¨res de la communication ğŸ¤Ÿ
</p>

<p align="center">
  Fait avec â¤ï¸ en Tunisie ğŸ‡¹ğŸ‡³
</p>
