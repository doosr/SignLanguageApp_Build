# SignLanguage - Traduction de la Langue des Signes en Temps RÃ©el

## ðŸ“± Description

Ce rapport prÃ©sente le dÃ©veloppement de **SignLanguage**, une application mobile innovante de traduction de la langue des signes en temps rÃ©el, rÃ©alisÃ©e durant un stage de perfectionnement d'un mois Ã  la PÃ©piniÃ¨re d'Entreprises APII Mahdia (janvier 2026).

SignLanguage utilise l'intelligence artificielle (MediaPipe + TensorFlow Lite) pour reconnaÃ®tre les gestes de la main et les traduire instantanÃ©ment en texte et en parole dans trois langues (franÃ§ais, anglais, arabe). L'application atteint **90.3% de prÃ©cision** pour les lettres et **78.5% pour les mots**, avec une latence de seulement **75 millisecondes**.

Le projet combine dÃ©veloppement mobile (Flutter), apprentissage automatique (CNN, LSTM), vision par ordinateur (MediaPipe) et IoT (ESP32-CAM). Il rÃ©pond Ã  un besoin social rÃ©el en facilitant la communication pour environ **100 000 personnes sourdes en Tunisie**.

## âœ¨ FonctionnalitÃ©s

### Mode Reconnaissance (Gestes â†’ Texte/Parole)

- âœ… **Reconnaissance en temps rÃ©el** des gestes de la main
- âœ… **DÃ©tection de lettres** (A-Z, alphabet langue des signes)
- âœ… **DÃ©tection de mots** (vocabulaire courant)
- âœ… **Support multilingue** : FranÃ§ais, English, Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- âœ… **SynthÃ¨se vocale (TTS)** pour prononcer le texte traduit
- âœ… **Interface accessible** avec emojis pour personnes sourdes
- âœ… **Mode ESP32-CAM** pour camÃ©ra externe

### ðŸ†• Mode Inverse (Texte â†’ Gestes) - Ã€ AJOUTER
>
> **FonctionnalitÃ© Ã  dÃ©velopper** : Permettre Ã  l'utilisateur d'Ã©crire du texte et afficher les gestes correspondants de la langue des signes lettre par lettre.
>
> **Objectif** : Une personne entendante Ã©crit un message, et l'application montre les gestes Ã  effectuer pour communiquer avec une personne sourde.
>
> **ImplÃ©mentation prÃ©vue** :
>
> - Interface de saisie texte
> - Animation ou images des gestes pour chaque lettre
> - Lecture sÃ©quentielle lettre par lettre
> - ContrÃ´le de vitesse d'affichage

## ðŸŽ¯ Performance

| MÃ©trique | Valeur | Objectif |
|----------|--------|----------|
| PrÃ©cision Lettres | **90.3%** | â‰¥85% âœ… |
| PrÃ©cision Mots | **78.5%** | â‰¥75% âœ… |
| Latence | **75ms** | <100ms âœ… |
| FPS | **24** | â‰¥20 âœ… |
| Langues supportÃ©es | **3** | FR/EN/AR âœ… |
| Taille APK | **42 MB** | <50MB âœ… |

## ðŸ› ï¸ Technologies

- **Flutter 3.16**: DÃ©veloppement mobile cross-platform
- **MediaPipe Hands**: DÃ©tection de 21 landmarks de la main
- **TensorFlow Lite**: ModÃ¨les d'IA on-device (CNN pour lettres, LSTM pour mots)
- **ESP32-CAM**: Module camÃ©ra IoT pour capture distante
- **Text-to-Speech**: SynthÃ¨se vocale multilingue
- **Translator**: Traduction FR/EN/AR

## ðŸ“¦ Installation

1. **Cloner le dÃ©pÃ´t**

```bash
git clone https://github.com/votre-nom/SignLanguage.git
cd SignLanguage
```

1. **Installer les dÃ©pendances Flutter**

```bash
cd flutter_app
flutter pub get
```

1. **Copier les modÃ¨les TFLite**

```bash
# Les modÃ¨les sont dans flutter_app/assets/
# - letter_classifier.tflite
# - word_classifier.tflite
# - labels.txt
```

1. **Lancer l'application**

```bash
flutter run
```

## ðŸ”¬ Collecte de DonnÃ©es et EntraÃ®nement

### 1. CrÃ©er le Dataset

```bash
python create_dataset.py
# Suivez les gestes devant la webcam
# GÃ©nÃ¨re: data.pickle (3000+ Ã©chantillons)
```

### 2. EntraÃ®ner les ModÃ¨les

```bash
python train_classifier.py
# GÃ©nÃ¨re: letter_classifier.tflite (90.3% prÃ©cision)
#         word_classifier.tflite (78.5% prÃ©cision)
```

### 3. Tester l'InfÃ©rence

```bash
python inference_classifier.py  # Mode lettres
python inference_sequence.py    # Mode mots
```

## ðŸ“ Structure du Projet

```
SignLanguage/
â”œâ”€â”€ flutter_app/              # Application mobile Flutter
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ main.dart        # Code principal
â”‚   â”œâ”€â”€ assets/              # ModÃ¨les TFLite
â”‚   â””â”€â”€ pubspec.yaml
â”œâ”€â”€ esp32_cam/               # Firmware ESP32-CAM
â”‚   â””â”€â”€ esp32_cam_stream.ino
â”œâ”€â”€ create_dataset.py        # Collecte de donnÃ©es
â”œâ”€â”€ train_classifier.py      # EntraÃ®nement modÃ¨les
â”œâ”€â”€ inference_classifier.py  # Test lettres
â”œâ”€â”€ inference_sequence.py    # Test mots
â””â”€â”€ README.md
```

## ðŸŒ Mots-clÃ©s

`Langue des signes` â€¢ `Intelligence artificielle` â€¢ `Flutter` â€¢ `MediaPipe` â€¢ `TensorFlow Lite` â€¢ `AccessibilitÃ©` â€¢ `IoT` â€¢ `ESP32-CAM` â€¢ `Reconnaissance gestuelle` â€¢ `Vision par ordinateur` â€¢ `Inclusion sociale` â€¢ `Application mobile` â€¢ `Temps rÃ©el` â€¢ `On-device AI`

## ðŸ“Š Utilisation

1. **Lancer l'app SignLanguage**
2. **SÃ©lectionner le mode** : ðŸ”¤ Lettres ou ðŸ’¬ Mots
3. **Choisir la langue** : ðŸ‡«ðŸ‡· FR / ðŸ‡¬ðŸ‡§ EN / ðŸ‡¹ðŸ‡³ AR
4. **Faire des gestes** devant la camÃ©ra
5. **Voir la traduction** s'afficher en temps rÃ©el
6. **Ã‰couter** la synthÃ¨se vocale

## ðŸ† Impact Social

- **100 000 personnes sourdes** en Tunisie peuvent bÃ©nÃ©ficier de cette solution
- **Gratuit et accessible** : pas besoin d'interprÃ¨te (50-100 DT/h)
- **Support de l'arabe** : innovation rare pour la communautÃ© maghrÃ©bine
- **On-device** : fonctionne sans internet
- **Interface accessible** : emojis pour faciliter l'usage

## ðŸš€ Perspectives

### Court terme (3-6 mois)

- [ ] Extension vocabulaire (50 mots)
- [ ] Mode sombre/clair
- [ ] DÃ©ploiement Google Play Store
- [ ] **Mode inverse : Texte â†’ Gestes**

### Moyen terme (6-12 mois)

- [ ] Reconnaissance expressions faciales
- [ ] Grammaire LSF
- [ ] DÃ©ploiement iOS

### Long terme (1-2 ans)

- [ ] Reconnaissance continue
- [ ] RÃ©alitÃ© augmentÃ©e
- [ ] Support ASL, BSL, autres langues des signes

## ðŸ“„ Licence

MIT License

## ðŸ‘¨â€ðŸ’» Auteur

Projet rÃ©alisÃ© dans le cadre d'un stage de perfectionnement  
**PÃ©piniÃ¨re d'Entreprises APII Mahdia** (Janvier 2026)  
**ISET Mahdia** - 2024-2025

## ðŸ™ Remerciements

- PÃ©piniÃ¨re d'Entreprises APII Mahdia
- Programme "startup APII" (Janvier 2026)
- ISET Mahdia
- CommunautÃ© sourde tunisienne
